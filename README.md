CSc 8830 â€“ Computer Vision
Assignment 5â€“6: Motion Tracking & Real-Time Object Tracking

Student: Victor Solomon
Course: CSc 8830 â€“ Computer Vision
Instructor: Dr. Ashwin Ashok
Institution: Georgia State University

ğŸ“Œ Overview

This repository contains all code, derivations, and demonstration material for Assignment 5â€“6 in CSc 8830: Computer Vision.
The assignment consists of:

Motion Tracking Theory

Derivation of the optical flow equation from first principles

Manual computation of motion estimates using two consecutive frames

Real-Time Object Tracking Implementations

(i) Marker-based tracking (Aruco / QR markers)

(ii) Markerless tracking using Lucasâ€“Kanade optical flow

(iii) Segmentation-based tracking using SAM2 (segmentation generated offline and played back in real-time via NPZ masks)

A video demonstration of all three tracking systems, as well as a complete PDF report with derivations and example calculations, is included as part of the assignment submission.

ğŸ“‚ Repository Structure
assignment5-6/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ marker_tracker.py          # ArUco marker-based tracking
â”‚   â”œâ”€â”€ markerless_tracker.py      # Lucasâ€“Kanade feature tracking
â”‚   â”œâ”€â”€ sam2_tracker.py            # SAM2 segmentation-based tracking (offline masks)
â”‚   â”œâ”€â”€ utils.py                   # Shared webcam/visualization helpers
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ frames/                    # Frames extracted from Problem 1 videos (for motion calc)
â”‚   â”œâ”€â”€ videos/                    # Optional prerecorded videos for SAM2 demo
â”‚   â”œâ”€â”€ sam2_masks.npz             # Offline segmentation masks for SAM2 tracking
â”‚   â””â”€â”€ markers/                   # Printable ArUco markers
â”‚
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ assignment5-6.pdf          # Full derivations + manual computation + results
â”‚   â””â”€â”€ figures/                   # Gradients, flow matrices, screenshots
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ demo_output/               # Screenshots, tracked sequences
â”‚   â””â”€â”€ demo_video.mp4             # Recorded demonstration
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # You are here

ğŸ”§ Installation & Setup
1. Create and activate environment
conda create -n cv56 python=3.10 -y
conda activate cv56
pip install -r requirements.txt

2. Required Python Packages
opencv-python
numpy
matplotlib
torch               # required only for SAM2 (if generating new masks)


If using SAM2 to generate masks offline, SAM2 must be installed separately from Metaâ€™s repository.

â–¶ï¸ Running Each Tracking System
1. Marker-Based Tracking (Aruco)
python src/marker_tracker.py


This script:

Opens your webcam

Detects ArUco markers

Tracks their 2D position in real time

Draws corners, ID numbers, and center points

You may print markers from data/markers/.

2. Markerless Tracking (Lucasâ€“Kanade Optical Flow)
python src/markerless_tracker.py


This script:

Detects Shi-Tomasi corners

Tracks features over time using pyramidal Lucasâ€“Kanade

Draws motion trails and reinitializes when tracking is lost

Press r to reset feature detection. Press q to quit.

3. SAM2 Segmentation-Based Tracking

Prerequisite: Precomputed SAM2 masks stored in data/sam2_masks.npz.

Run:

python src/sam2_tracker.py


This script:

Loads a prerecorded video and segmentation masks

Overlays segmentation on each frame

Computes bounding boxes of segmented objects

Produces a real-time visualization

This satisfies the requirement to use SAM2 segmentation offline while demonstrating it online.

âœï¸ Part (a) â€” Motion Tracking Equation & Manual Computation

Section 1 of the PDF contains:

Full derivation of the brightness constancy assumption

Taylor expansion leading to

ğ¼
ğ‘¥
ğ‘¢
+
ğ¼
ğ‘¦
ğ‘£
+
ğ¼
ğ‘¡
=
0
I
x
	â€‹

u+I
y
	â€‹

v+I
t
	â€‹

=0

Matrix formulation for a local Lucasâ€“Kanade window

Manual calculations using two actual consecutive frames

Computation of 
ğ¼
ğ‘¥
,
ğ¼
ğ‘¦
,
ğ¼
ğ‘¡
I
x
	â€‹

,I
y
	â€‹

,I
t
	â€‹


Construction of the matrix 
ğ´
A

Solving 
(
ğ´
âŠ¤
ğ´
)
ğ‘¤
=
ğ´
âŠ¤
ğ‘
(A
âŠ¤
A)w=A
âŠ¤
b

Final numerical motion estimate 
(
ğ‘¢
,
ğ‘£
)
(u,v)

All steps are shown in detail as required by the assignment.

ğŸ¥ Demonstration Video

The demonstration video (demo_video.mp4) includes:

Marker-based tracking

Markerless optical flow tracking

SAM2 segmentation-based tracking

Each system is shown operating on live webcam input or prerecorded video.

The video is uploaded separately to Google Classroom as required.

ğŸ“‘ Assignment Report

The final PDF includes:

Derivation of the motion equation

Manual computation of motion for two frames

Explanation of each tracking method

Screenshots and analysis

References (per assignment requirement)

The PDF is located in:

report/assignment5-6.pdf

